{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import data_read as data_utils\n",
    "import model as model_parse\n",
    "import perception as model_utils\n",
    "import dynamics as dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if logging is None:\n",
    "    # The logging module may have been unloaded when __del__ is called.\n",
    "    log_fn = print\n",
    "else:\n",
    "    log_fn = logging.warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters.\n",
    "seed = 0\n",
    "tf.random.set_seed(seed)\n",
    "batch_size = 1\n",
    "num_frames = 15\n",
    "num_slots = 8\n",
    "slot_size = 32\n",
    "sample_steps_num = 100\n",
    "learning_sample = 0.04\n",
    "resolution = (128, 128)\n",
    "patch_size = (1, 3, 5, 15)\n",
    "model_dir = \"checkpoint/XPL/\"\n",
    "perception_dir = \"checkpoint/perception/\"\n",
    "\n",
    "decode_type = \"SBTD\"\n",
    "encode_type = \"ViT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ED(num_frames, resolution, batch_size, num_slots, slot_size,\n",
    "                 encode_type, decode_type, file):\n",
    "    model_pre = model_utils.build_model(resolution,\n",
    "                                        batch_size * num_slots * num_frames,\n",
    "                                        num_channels=4,\n",
    "                                        slot_size=slot_size,\n",
    "                                        decode_type=decode_type,\n",
    "                                        encode_type=encode_type)\n",
    "    ckpt_pre = tf.train.Checkpoint(network=model_pre)\n",
    "    ckpt_manager_pre = tf.train.CheckpointManager(ckpt_pre,\n",
    "                                                  directory=file,\n",
    "                                                  max_to_keep=5)\n",
    "    if ckpt_manager_pre.latest_checkpoint:\n",
    "        ckpt_pre.restore(ckpt_manager_pre.latest_checkpoint).expect_partial()\n",
    "        log_fn(\"Restored from {}\".format(ckpt_manager_pre.latest_checkpoint))\n",
    "    model_enc = model_pre.get_layer(\"ObjectEncoder\")\n",
    "    model_dec = model_pre.get_layer(\"ObjectDecoder\")\n",
    "    return model_enc, model_dec, model_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enc, model_dec, model_pre = get_video_ED(num_frames, resolution, batch_size,\n",
    "                               num_slots, slot_size, encode_type,\n",
    "                               decode_type, perception_dir)\n",
    "optimizer_sample = tf.keras.optimizers.Adam(learning_sample,\n",
    "                                            epsilon=1e-08)\n",
    "model_sample = model_parse.build_sample_model(num_frames,\n",
    "                                              patch_size,\n",
    "                                              batch_size,\n",
    "                                              num_slots,\n",
    "                                              slot_size,\n",
    "                                              initial=True)\n",
    "model_reason = dy.build_IN_LSTM(batch_size,\n",
    "                                num_slots,\n",
    "                                slot_size,\n",
    "                                num_frames=num_frames,\n",
    "                                use_camera=False)\n",
    "model_fast = model_parse.build_fast_model(batch_size, num_frames,\n",
    "                                          num_slots, slot_size)\n",
    "model_new = model_parse.build_fast_model(batch_size, num_frames,\n",
    "                                         num_slots, slot_size)\n",
    "ckpt = tf.train.Checkpoint(network=model_reason)\n",
    "ckpt_F = tf.train.Checkpoint(network=model_fast)\n",
    "ckpt_N = tf.train.Checkpoint(network=model_new)\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint=ckpt,\n",
    "                                          directory=model_dir,\n",
    "                                          max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "ckpt_manager_F = tf.train.CheckpointManager(checkpoint=ckpt_F,\n",
    "                                            directory=model_dir +\n",
    "                                            \"/fast\",\n",
    "                                            max_to_keep=5)\n",
    "ckpt_F.restore(ckpt_manager_F.latest_checkpoint)\n",
    "ckpt_manager_N = tf.train.CheckpointManager(checkpoint=ckpt_N,\n",
    "                                            directory=model_dir +\n",
    "                                            \"/new\",\n",
    "                                            max_to_keep=5)\n",
    "ckpt_N.restore(ckpt_manager_N.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    log_fn(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    log_fn(\"Initializing from scratch.\")\n",
    "if ckpt_manager_F.latest_checkpoint:\n",
    "    log_fn(\"Restored from {}\".format(ckpt_manager_F.latest_checkpoint))\n",
    "else:\n",
    "    log_fn(\"Initializing from scratch.\")\n",
    "if ckpt_manager_N.latest_checkpoint:\n",
    "    log_fn(\"Restored from {}\".format(ckpt_manager_N.latest_checkpoint))\n",
    "else:\n",
    "    log_fn(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalize(x):\n",
    "    \"\"\"Renormalize from [-1, 1] to [0, 1].\"\"\"\n",
    "    x = tf.clip_by_value(x, -1.0, 1.0)\n",
    "    return x / 2. + 0.5\n",
    "\n",
    "def data_init(img, mask):\n",
    "    object_img = tf.expand_dims(img, axis=2) * mask + (1 - mask)\n",
    "    mask_mean = tf.reduce_sum(mask, axis=[3, 4])\n",
    "    mask_sum = tf.reduce_sum(mask, axis=2)\n",
    "    mask_sum = tf.clip_by_value(mask_sum, 0.0, 1.0)\n",
    "    new_image = img * mask_sum + (1 - mask_sum)\n",
    "    object_img = tf.reshape(object_img,\n",
    "                            shape=[-1] + object_img.shape.as_list()[3:])\n",
    "    mask_mean = tf.where(mask_mean > 4, 1.0, 0.0)\n",
    "    return object_img, new_image, mask_sum, mask_mean\n",
    "\n",
    "def visualize_objects(objects, mask_sum):\n",
    "    DM_factor = -1000.0\n",
    "    (B, F, N, V) = objects.shape\n",
    "    objects = tf.reshape(objects, shape=[-1, V])\n",
    "    recons, depth, slots = model_dec(objects)\n",
    "    recons = tf.reshape(recons, shape=[-1, F, N] + recons.shape.as_list()[1:])\n",
    "    depth = tf.reshape(depth, shape=[-1, F, N] + depth.shape.as_list()[1:])\n",
    "    masks = tf.nn.softmax(depth * DM_factor, axis=2)\n",
    "    masks = masks * tf.expand_dims(mask_sum, axis=2)\n",
    "    recons_image = tf.reduce_sum(recons * masks, axis=2)\n",
    "    recons_image = recons_image * mask_sum + 1.0 * (1 - mask_sum)\n",
    "    return recons_image, recons, depth\n",
    "\n",
    "\n",
    "def encode_out(batch):\n",
    "    DM_factor = -1000.0\n",
    "    image, new_image, mask_sum, mask_mean = data_init(batch['image'],\n",
    "                                                      batch['mask'])\n",
    "    recons, depth, slots, kl_z = model_pre(image)\n",
    "    pre_slots = model_enc(image)\n",
    "    pre_slots = tf.nn.sigmoid(pre_slots)\n",
    "    pre_slots = tf.reshape(pre_slots,\n",
    "                           shape=[-1, num_frames, num_slots, slot_size * 2])\n",
    "    pre_slots_dist = (pre_slots[:, :, :, :slot_size] * 6.0 - 3.0,\n",
    "                      pre_slots[:, :, :, slot_size:] * 3.0)\n",
    "    dist1 = tfd.Normal(pre_slots_dist[0], pre_slots_dist[1])\n",
    "    objects_pre = dist1.sample()\n",
    "    recons_image, recons, depth = visualize_objects(objects_pre, mask_sum)\n",
    "    return recons_image, recons, depth\n",
    "\n",
    "\n",
    "def fast_out(batch):\n",
    "    DM_factor = -1000.0\n",
    "    img = batch['image']\n",
    "    mask = batch['mask']\n",
    "    image, new_image, mask_sum, mask_mean = data_init(img, mask)\n",
    "    pre_slots = model_enc(image)\n",
    "    B = mask.shape[0]\n",
    "    pre_slots = tf.nn.sigmoid(pre_slots)\n",
    "    pre_slots = tf.reshape(pre_slots,\n",
    "                           shape=[-1, num_frames, num_slots, slot_size * 2])\n",
    "    random_noise = tf.reduce_sum(mask, axis=[1, 3, 4, 5])\n",
    "    random_slots = tf.argsort(random_noise, axis=1)\n",
    "    restore_slots = tf.argsort(random_slots, axis=1)\n",
    "    mask = tf.gather(mask, random_slots, axis=2, batch_dims=-1)\n",
    "    pre_slots = tf.gather(pre_slots, random_slots, axis=2, batch_dims=-1)\n",
    "    mask_mean = tf.reduce_sum(mask, axis=[3, 4])\n",
    "    mask_mean = tf.where(mask_mean > 4, 1.0, 0.0)\n",
    "    mask_mean = mask_mean + tf.cast(\n",
    "        tf.reduce_sum(mask_mean, axis=1, keepdims=True) < 1, tf.float32)\n",
    "    mask_axes = tf.concat([\n",
    "        tf.zeros([1, num_frames, 1, 1]),\n",
    "        tf.ones([1, num_frames, num_slots - 1, 1])\n",
    "    ],\n",
    "                          axis=2)\n",
    "    mask_axes = tf.tile(mask_axes, [B, 1, 1, 1])\n",
    "    pre_slots_dist = (pre_slots[:, :, :, :slot_size] * 6.0 - 3.0,\n",
    "                      pre_slots[:, :, :, slot_size:] * 3.0)\n",
    "    dist1 = tfd.Normal(pre_slots_dist[0], pre_slots_dist[1])\n",
    "    objects_pre = dist1.sample()\n",
    "    objects_init = model_fast((objects_pre, mask_mean), training=False)\n",
    "    objects_init = model_new((objects_init, mask_axes), training=False)\n",
    "    objects_init = tf.gather(objects_init,\n",
    "                             restore_slots,\n",
    "                             axis=2,\n",
    "                             batch_dims=-1)\n",
    "    recons_image, recons, depth = visualize_objects(objects_init, mask_sum)\n",
    "    return recons_image, recons, depth\n",
    "\n",
    "def slow_out(batch):\n",
    "    DM_factor = -1000.0\n",
    "    multi1 = 1.0\n",
    "    multi2 = 0.01\n",
    "    img = batch['image']\n",
    "    mask = batch['mask']\n",
    "    image, new_image, mask_sum, mask_mean = data_init(img, mask)\n",
    "    pre_slots = model_enc(image)\n",
    "    B = mask.shape[0]\n",
    "    pre_slots = tf.nn.sigmoid(pre_slots)\n",
    "    pre_slots = tf.reshape(pre_slots,\n",
    "                           shape=[-1, num_frames, num_slots, slot_size * 2])\n",
    "    random_noise = tf.reduce_sum(mask, axis=[1, 3, 4, 5])\n",
    "    random_slots = tf.argsort(random_noise, axis=1)\n",
    "    restore_slots = tf.argsort(random_slots, axis=1)\n",
    "    mask = tf.gather(mask, random_slots, axis=2, batch_dims=-1)\n",
    "    pre_slots = tf.gather(pre_slots, random_slots, axis=2, batch_dims=-1)\n",
    "    mask_mean = tf.reduce_sum(mask, axis=[3, 4])\n",
    "    mask_mean = tf.where(mask_mean > 4, 1.0, 0.0)\n",
    "    mask_mean = mask_mean + tf.cast(\n",
    "        tf.reduce_sum(mask_mean, axis=1, keepdims=True) < 1, tf.float32)\n",
    "    mask_axes = tf.concat([\n",
    "        tf.zeros([1, num_frames, 1, 1]),\n",
    "        tf.ones([1, num_frames, num_slots - 1, 1])\n",
    "    ],\n",
    "                          axis=2)\n",
    "    mask_axes = tf.tile(mask_axes, [B, 1, 1, 1])\n",
    "    pre_slots_dist = (pre_slots[:, :, :, :slot_size] * 6.0 - 3.0,\n",
    "                      pre_slots[:, :, :, slot_size:] * 3.0)\n",
    "    dist1 = tfd.Normal(pre_slots_dist[0], pre_slots_dist[1])\n",
    "    objects_pre = dist1.sample()\n",
    "    objects_init = model_fast((objects_pre, mask_mean), training=False)\n",
    "    objects_init = model_new((objects_init, mask_axes), training=False)\n",
    "    mask_mean = mask_mean * mask_axes\n",
    "    for _ in range(sample_steps_num):\n",
    "        # Get the prediction of the models and compute the loss.\n",
    "        with tf.GradientTape() as tape:\n",
    "            model_sample.trainable = True\n",
    "            model_reason.trainable = False\n",
    "            model_fast.trainable = False\n",
    "            model_new.trainable = False\n",
    "            _, objects = model_sample(objects_pre, training=True)\n",
    "            objects = objects + objects_init\n",
    "            objects = pre_slots_dist[0] * mask_mean + objects * (1 - mask_mean)\n",
    "            objects_2 = model_reason(objects)\n",
    "            objects_2 = objects + objects_2\n",
    "            objects_2 = tf.roll(objects_2, shift=1, axis=1)\n",
    "            loss1 = tf.math.squared_difference(objects_2, objects)\n",
    "            loss1 = loss1[:, 1:, :, :]\n",
    "            loss2 = tf.math.squared_difference(objects_init, objects)\n",
    "            loss1 = tf.reduce_sum(loss1, axis=[1, 2, 3])\n",
    "            loss2 = tf.reduce_sum(loss2, axis=[1, 2, 3])\n",
    "            loss = loss1 * multi1 + loss2 * multi2\n",
    "        # Get and apply gradients.\n",
    "        gradients = tape.gradient(loss, model_sample.trainable_weights)\n",
    "        optimizer_sample.apply_gradients(\n",
    "            zip(gradients, model_sample.trainable_weights),\n",
    "            experimental_aggregate_gradients=False)\n",
    "    _, objects = model_sample(objects_pre, training=False)\n",
    "    objects = objects + objects_init\n",
    "    objects = pre_slots_dist[0] * mask_mean + objects * (1 - mask_mean)\n",
    "    objects = tf.gather(objects, restore_slots, axis=2, batch_dims=-1)\n",
    "    recons_image, recons, depth = visualize_objects(objects, mask_sum)\n",
    "    return recons_image, recons, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_ds =  data_utils.debug_iterator(batch_size,\n",
    "                                             split=\"collision\",\n",
    "                                             shuffle=False)\n",
    "iterator = iter(collision_ds)\n",
    "batch = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, num_frames, figsize=(2*num_frames,2))\n",
    "for i in range(num_frames):\n",
    "  ax[i].imshow(renormalize(batch['image'][0,i][...,:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_combined, recons, depth = encode_out(batch)\n",
    "fig, ax = plt.subplots(num_frames, num_slots + 2, figsize=(15, 2 * num_frames))\n",
    "for i in range(num_frames):\n",
    "    ax[i, 0].imshow(renormalize(batch['image'][0,i][..., :3]))\n",
    "    # ax[i,0].set_title('Image')\n",
    "    ax[i, 1].imshow(renormalize(recon_combined[0,i][..., :3]))\n",
    "    # ax[i,1].set_title('Recon.')\n",
    "    # recons,masks=sort(recons[i],masks[i])\n",
    "    for j in range(num_slots):\n",
    "        ax[i, j + 2].imshow(renormalize(recons[0, i, j][..., :3]))\n",
    "# ax[0].imshow(image)\n",
    "ax[0, 0].set_title('Image')\n",
    "# ax[1].imshow(recon_combined)\n",
    "ax[0, 1].set_title('Recon.')\n",
    "for i in range(num_slots):\n",
    "    # ax[i + 2].imshow(recons[i] * masks[i] + (1 - masks[i]))\n",
    "    #ax[i + 2].imshow(recons[i])\n",
    "    ax[0, i + 2].set_title('Slot %s' % str(i + 1))\n",
    "for i in range(num_frames):\n",
    "    for j in range(num_slots + 2):\n",
    "        ax[i, j].grid(False)\n",
    "        ax[i, j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_combined, recons, depth = fast_out(batch)\n",
    "fig, ax = plt.subplots(num_frames, num_slots + 2, figsize=(15, 2 * num_frames))\n",
    "for i in range(num_frames):\n",
    "    ax[i, 0].imshow(renormalize(batch['image'][0,i][..., :3]))\n",
    "    # ax[i,0].set_title('Image')\n",
    "    ax[i, 1].imshow(renormalize(recon_combined[0,i][..., :3]))\n",
    "    # ax[i,1].set_title('Recon.')\n",
    "    # recons,masks=sort(recons[i],masks[i])\n",
    "    for j in range(num_slots):\n",
    "        ax[i, j + 2].imshow(renormalize(recons[0, i, j][..., :3]))\n",
    "# ax[0].imshow(image)\n",
    "ax[0, 0].set_title('Image')\n",
    "# ax[1].imshow(recon_combined)\n",
    "ax[0, 1].set_title('Recon.')\n",
    "for i in range(num_slots):\n",
    "    # ax[i + 2].imshow(recons[i] * masks[i] + (1 - masks[i]))\n",
    "    #ax[i + 2].imshow(recons[i])\n",
    "    ax[0, i + 2].set_title('Slot %s' % str(i + 1))\n",
    "for i in range(num_frames):\n",
    "    for j in range(num_slots + 2):\n",
    "        ax[i, j].grid(False)\n",
    "        ax[i, j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_combined, recons, depth = slow_out(batch)\n",
    "fig, ax = plt.subplots(num_frames, num_slots + 2, figsize=(15, 2 * num_frames))\n",
    "for i in range(num_frames):\n",
    "    ax[i, 0].imshow(renormalize(batch['image'][0,i][..., :3]))\n",
    "    # ax[i,0].set_title('Image')\n",
    "    ax[i, 1].imshow(renormalize(recon_combined[0,i][..., :3]))\n",
    "    # ax[i,1].set_title('Recon.')\n",
    "    # recons,masks=sort(recons[i],masks[i])\n",
    "    for j in range(num_slots):\n",
    "        ax[i, j + 2].imshow(renormalize(recons[0, i, j][..., :3]))\n",
    "# ax[0].imshow(image)\n",
    "ax[0, 0].set_title('Image')\n",
    "# ax[1].imshow(recon_combined)\n",
    "ax[0, 1].set_title('Recon.')\n",
    "for i in range(num_slots):\n",
    "    # ax[i + 2].imshow(recons[i] * masks[i] + (1 - masks[i]))\n",
    "    #ax[i + 2].imshow(recons[i])\n",
    "    ax[0, i + 2].set_title('Slot %s' % str(i + 1))\n",
    "for i in range(num_frames):\n",
    "    for j in range(num_slots + 2):\n",
    "        ax[i, j].grid(False)\n",
    "        ax[i, j].axis('off')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4511dba33a7e455faeb8fcd9c841305e70d250a31b7cae6b1a9cf3757521dae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('SlotAttention')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
